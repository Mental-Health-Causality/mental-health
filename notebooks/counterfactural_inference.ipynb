{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import dataset utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import importlib\n",
    "if importlib.util.find_spec('ipywidgets') is not None:\n",
    "    from tqdm.auto import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('../data/final.csv', sep=';')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suic = dataframe[['Suicidio','sexo', 'Estado_civil', 'Tipo_Resid','idade',\n",
    "                   'Alcoolatra', 'Droga', 'Suic_familia', 'Dep_familia',\n",
    "                   'Alc_familia', 'Drog_familia',\n",
    "                   'Neuro',\n",
    "                   'psiquiatrica', 'Anos educacao formal', 'Capaz de desfrutar das coisas',\n",
    "                   'Impacto de sua familia e amigos',\n",
    "                   'Capaz de tomar decisões importantes', 'Estudante',\n",
    "                   'Insonia',\n",
    "                   'Deprimido', 'Ansiedade',\n",
    "                   'Perda de insights', 'Apetite', 'Perda de peso', 'Ansiedade somática',\n",
    "                   'Hipocondriase', 'Sentimentos_culpa', \n",
    "                   'Trabalho e interesses', 'Energia', 'Lentidao pensamento e fala',\n",
    "                   'Agitação', 'Libido', 'Pontuação total', 'TOC']]\n",
    "\n",
    "df_suic['sexo'].replace({'M': 0, 'F': 1}, inplace=True)\n",
    "df_suic['sexo'].fillna(0, inplace=True)\n",
    "\n",
    "df_suic.dropna(inplace=True)\n",
    "df_suic = df_suic.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    " \n",
    "  def __init__(self, input_dataframe, split=\"train\", target=\"Suicidio\", ignore_columns=[], train_ratio=0.8):\n",
    "    \n",
    "    self.split = split\n",
    "    self.target = target\n",
    "    self.ignore_columns = ignore_columns\n",
    "\n",
    "    for coll in self.ignore_columns:\n",
    "      if coll in input_dataframe.columns:\n",
    "        input_dataframe = input_dataframe.drop(coll, axis=1)\n",
    "\n",
    "    self.classification_dim = len(input_dataframe[self.target].unique())\n",
    "    self.data_dim = len(input_dataframe.columns) - 1\n",
    "    self.embbeding_dim = input_dataframe.max().max() + 1\n",
    "\n",
    "    y = input_dataframe[target].values\n",
    "    x = input_dataframe.drop(target, axis = 1).values\n",
    "\n",
    "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=42)\n",
    "\n",
    "  def __len__(self):\n",
    "    if self.split == \"train\":\n",
    "      return len(self.x_train)\n",
    "    elif self.split == \"test\":\n",
    "      return len(self.x_test)\n",
    "    else:\n",
    "      raise ValueError(\"Split must be train or test\")\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    if self.split == \"train\":\n",
    "      return torch.tensor(self.x_train[idx], dtype=torch.long), torch.tensor(self.y_train[idx], dtype=torch.long)\n",
    "    elif self.split == \"test\":\n",
    "      return torch.tensor(self.x_test[idx], dtype=torch.long), torch.tensor(self.y_test[idx], dtype=torch.long)\n",
    "    else:\n",
    "      raise ValueError(\"Split must be train or test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(df_suic, split=\"train\", target=\"Suicidio\", ignore_columns=[], train_ratio=0.8)\n",
    "test_dataset = MyDataset(df_suic, split=\"test\", target=\"Suicidio\", ignore_columns=[], train_ratio=0.8)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a MLP model with an embedding layer\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, embedding_out, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(embedding_dim, embedding_out)\n",
    "        self.fc1 = nn.Linear(embedding_out*input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# test the model\n",
    "example_batch = next(iter(train_loader))\n",
    "example_data, example_targets = example_batch\n",
    "model = MLP(input_dim=train_dataset.data_dim, embedding_dim=110, embedding_out=64, hidden_dim=128, output_dim=train_dataset.classification_dim)\n",
    "print(model)\n",
    "print(\"Batch shape:\", example_data.shape)\n",
    "res = model(example_data)\n",
    "print(\"Output shape:\", res.shape)\n",
    "print(\"Output:\", res[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Lightning Module\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "class BaseModel(LightningModule):\n",
    "    \"\"\"A LightningModule organizes your PyTorch code into 6 sections:\n",
    "        - Computations (init)\n",
    "        - Validation loop (validation_step)\n",
    "        - Train loop (training_step)\n",
    "        - Test loop (test_step)\n",
    "        - Prediction Loop (predict_step)\n",
    "        - Optimizers and LR Schedulers (configure_optimizers)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, embedding_dim, embedding_out, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = MLP(input_dim, embedding_dim, embedding_out, hidden_dim, output_dim)\n",
    "\n",
    "    def step(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x).squeeze().float()\n",
    "        # loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        # L1 Loss\n",
    "        loss = F.l1_loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trainer\n",
    "from pytorch_lightning.trainer import Trainer\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = BaseModel(input_dim=train_dataset.data_dim, embedding_dim=train_dataset.embbeding_dim, embedding_out=64, hidden_dim=128, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import callbacks\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Initialize callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.00,\n",
    "    patience=10,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, early_stopping]\n",
    "\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(accelerator='gpu', devices=1, check_val_every_n_epoch=10, log_every_n_steps=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model ⚡\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('cml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71f78216db5cb2f09350fda35ad9d9668a66a927586f044b9adeddeb17c1df4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
